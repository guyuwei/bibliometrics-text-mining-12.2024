import matplotlib.pyplot as plt
import pandas as pd
import streamlit as st
import re
from datetime import datetime

from PIL.ImageOps import expand
from pandas.io.common import file_exists
from streamlit import session_state
from streamlit_option_menu import option_menu
import math
import numpy as np
import sys
import os

current_dir = os.path.dirname(os.path.realpath(__file__))
project_root = os.path.dirname(current_dir).replace("/Program","")
library_dir=project_root+ '/library/web_sources/'
picture_path=project_root+ '/output/picture'
csv_path= project_root+'/output/'

# sys.path.append(project_root)  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
#
# sys.path.append(os.path.join(project_root, 'Calculate_Anaysis'))
# sys.path.append(os.path.join(project_root, 'Documents_Processing'))
# sys.path.append(os.path.join(project_root, 'Result_Visualization'))
from Calculate_Anaysis.Calculate_Author import calculate_core_author_publication,calculate_number_of_authors_publication
from Calculate_Anaysis.Calculate_Country import calculate_collaboration_countries
from Calculate_Anaysis.Calculate_Publication import calculate_publications_per_year
from Calculate_Anaysis.Calculate_Sources import calculate_number_of_sources
from Calculate_Anaysis.Calculate_Keywords import calculate_number_of_keywords
from Calculate_Anaysis.Calculate_Reference import calculate_number_of_total_references_cited,filter_references_by_authors,extract_each_article_author_refauthor
from Calculate_Anaysis.Calculate_Citiation import calculate_number_of_total_Timescitedcount
from Calculate_Anaysis.Calculate_Year import exact_targetarticles_within_yearspan,calculate_age
from Result_Visualization.Descriptive_Statistics import Form_Information_Description,shift_edited_df_into_list
from Result_Visualization.Publications_and_Authors import draw_author_density_visualiaztion,draw_author_overlay_visualiaztion,draw_author_network_visualiaztion
from Documents_Processing.Uploading_Files import Load_TXT,Load_CSV,Load_Refine,Extract_Info_From_Refine
from Documents_Processing.Web_Format import st_header, st_subheader, st_selectbox, st_card, st_tags, st_radio, st_button, st_slider, st_checkbox, st_text_area, st_text_input, \
    st_multiselect, st_warning, st_markdown, st_latex, st_table, st_dataframe, st_sidebar_slider, st_file_uploader, st_expander,st_subsubheader,set_page_title_with_image

from Documents_Processing.Tab_Process import process_tabledescribe_tab,process_Publication_Author_Analysis_Tab,process_Publication_Author_Tab_Most_Productive,process_Overall_Information_Overview_Tab,process_Journay_Analysis_Tab,process_Country_Analysis_Tab
def Save_Form_to_Csv(df_name, df,autotext,csv_path=csv_path):
    user_input_path =csv_path
    user_input_name = st.text_input("è¯·è¾“å…¥" + df_name + "ä¿å­˜æ–‡ä»¶å",label_visibility="collapsed",value=autotext,).title()
    if user_input_name and not user_input_name.endswith('.csv'):
                user_input_name += '.csv'
    file_name =user_input_path+user_input_name
    col5, col6 = st.columns([1, 2])
    with col5:
        if st_button("Download " + df_name + " Table File"):
            df.to_csv(file_name, index=False, header=True)
            with col6:
                st.success(f"ğŸ‰{df_name} æˆæœä¿å­˜è‡³ï¼š{ file_name } æ–‡ä»¶ï¼")
                st.snow()

# å®šä¹‰æ»‘åŠ¨æ¡çš„å›è°ƒå‡½æ•°
def slider_callback():
    session_state_year= False

def process_wos_page_upload():
    st.subheader("ğŸ“ Upload Literature Data File")
    st.markdown("**è¯·ä¸Šä¼ æ–‡çŒ®æ•°æ®æ–‡ä»¶**")
    st.info("ğŸ’¡ æ”¯æŒWOSå¯¼å‡ºæ–‡ä»¶(.txt)ã€CSVæ•°æ®æ–‡ä»¶(.csv)ã€BibTeXæ–‡çŒ®æ–‡ä»¶(.bib)")
    uploaded_file = st.file_uploader(
        "é€‰æ‹©æ–‡çŒ®æ•°æ®æ–‡ä»¶", 
        type=["txt", "csv", "bib"], 
        key="wos_main_file"
    )
    
    st.markdown("---")
    st_header("ğŸ“Š Upload Refine File (Optional)")
    st.markdown("**å¯é€‰ï¼šä¸Šä¼ Excelæ ¼å¼çš„æ•°æ®ç²¾ç‚¼æ–‡ä»¶**")
    st.info("ğŸ’¡ å¯é€‰çš„Excelæ ¼å¼ç²¾ç‚¼æ–‡ä»¶ï¼Œç”¨äºæ•°æ®å¢å¼º")
    refine_file = st.file_uploader(
        "é€‰æ‹©ç²¾ç‚¼æ–‡ä»¶", 
        type=["xlsx"],
        key="wos_refine_file"
    )

    if uploaded_file is not None:
        file_exists = True
        try:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©è§£æå™¨
            if uploaded_file.name.endswith('.txt'):
                # ä½¿ç”¨å¢å¼ºçš„WOSè§£æå™¨
                try:
                    from .Uploading_Files import Load_TXT_Enhanced
                    df = Load_TXT_Enhanced(uploaded_file)
                except ImportError:
                    # å›é€€åˆ°åŸå§‹è§£æå™¨
                    df = Load_TXT(uploaded_file)
            elif uploaded_file.name.endswith('.csv'):
                df = Load_CSV(uploaded_file)
            elif uploaded_file.name.endswith('.bib'):
                # ä½¿ç”¨å¢å¼ºçš„æ–‡ä»¶ä¸Šä¼ å™¨åŠ è½½BIBæ–‡ä»¶
                try:
                    from .Enhanced_File_Uploader import load_file_universal
                    df = load_file_universal(uploaded_file)
                except ImportError:
                    st.error("BIBæ–‡ä»¶è§£æåŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æ¨¡å—å¯¼å…¥")
                    return pd.DataFrame(), False
            else:
                st.error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼ .txtã€.csvæˆ–.bibæ–‡ä»¶")
                return pd.DataFrame(), False
            
            # æ£€æŸ¥DataFrameæ˜¯å¦æœ‰æ•ˆ
            if df is None or df.empty:
                st.error("æ–‡ä»¶è§£æå¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
                return pd.DataFrame(), False
            
            if refine_file:
                try:
                    df_refine = Load_Refine(refine_file)
                    # å°†ä¼šè¯çŠ¶æ€å­˜å‚¨refineæ•°æ®
                    st.session_state['refine_data'] = Extract_Info_From_Refine(df_refine)
                except Exception as e:
                    st.warning(f"ç²¾ç‚¼æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
                    # å³ä½¿ç²¾ç‚¼æ–‡ä»¶å¤±è´¥ï¼Œä»ç„¶è¿”å›ä¸»æ•°æ®
            
            st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼è§£æåˆ° {len(df)} æ¡æ–‡çŒ®è®°å½•")
            return df, file_exists
            
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return pd.DataFrame(), False
    else:
        file_exists = False
        return pd.DataFrame(), file_exists
def process_wos_page_download(df):
    st.subheader("Field Parsing Result")
    st.dataframe(df, height=500, width=2800, use_container_width=True,selection_mode=["multi-row"])
    st_subsubheader("Database Description")
    number_of_total_articles = df.shape[0]
    count_result = {}  # æ•°æ®åº“çš„info
    missing_value_columns = st.multiselect('é€‰æ‹©éœ€è¦ç»Ÿè®¡çš„å‚æ•°:', df.columns,
                                           default=df.columns[:6],label_visibility="collapsed")
    if missing_value_columns:
        for para in missing_value_columns:
            count_result[para] = {"å…±è®¡": str(len(df[para].value_counts())),
                                  "ç¼ºå¤±å€¼": str(number_of_total_articles - len(
                                      df[para].value_counts())),
                                  "å‚æ•°ç±»å‹": type(df[para][0]).__name__}
        count_result = pd.DataFrame(count_result).sort_index(axis=1)
        st.dataframe(count_result,height=100,width=400,use_container_width=True)
    st_subsubheader("Selected Columns to Perform Text Minging")

    selected_columns = st.multiselect('é€‰æ‹©åˆ—:', df.columns, default=df.columns,label_visibility="collapsed")
    selected_df = df[selected_columns]
    st_subsubheader("Please enter the saved filename of the filtered table.".title())
    return selected_df



def process_database_page(a):

    st.subheader("Upload CSV Film")
    uploaded_file = st_file_uploader("ä¸Šä¼ è§£ææ–‡ä»¶ï¼šcsvæ ¼å¼", type=["csv"])
    if uploaded_file is not None:
        rawdf = Load_CSV(uploaded_file)
        st.dataframe(rawdf, height=500, width=2800,use_container_width=True)
        st.subheader("Data Analysis")
        sorted_data, years, publications_per_year = calculate_publications_per_year(rawdf)
        (start, stop) = st.slider(
                label="é€‰æ‹©çº³å…¥ç»Ÿè®¡åˆ†æçš„å¹´ä»½",  # æ»‘åŠ¨æ¡çš„æ ‡é¢˜ï¼Œæ˜¾ç¤ºç»™ç”¨æˆ·æç¤ºå…¶åŠŸèƒ½
                min_value=int(min(years)),  # æ»‘åŠ¨æ¡åŒºé—´çš„æœ€å°å€¼
                max_value=int(max(years)),  # æ»‘åŠ¨æ¡åŒºé—´çš„æœ€å¤§å€¼
                value=(                    int(min(years)) , int(max(years)) - 1),
                step=1,label_visibility="collapsed",on_change=slider_callback)
        df = exact_targetarticles_within_yearspan(rawdf, start, stop)  # æŒ‰ç…§å¹´ä»½æå–çš„è®¨è®ºèŒƒå›´å†…çš„æ–‡ç« 
        st.markdown("""
        <style>
            .stTabs [data-baseweb="tab-list"] button [data-testid="stMarkdownContainer"] p {
                font-size: 20px;
            }
        </style>
        """, unsafe_allow_html=True)

        # åˆ›å»ºé«˜çº§æ„Ÿæ ‡ç­¾é¡µ
        st.markdown("""
        <div style="margin-bottom: 30px;">
            <h3 style="color: #2C3E50; font-size: 1.8rem; font-weight: 400; margin-bottom: 20px; text-align: center; letter-spacing: 0.5px;">ğŸ“Š æ•°æ®åˆ†ææ¨¡å—</h3>
            <div style="width: 100px; height: 2px; background: linear-gradient(90deg, #C0D6EA 0%, #B5A8CA 100%); margin: 0 auto 30px; border-radius: 1px;"></div>
        </div>
        """, unsafe_allow_html=True)
        
        tabs = st.tabs([
            'ğŸ“ˆ æ€»ä½“ä¿¡æ¯æ¦‚è§ˆ',
            'ğŸ‘¥ å‘æ–‡ä½œè€…åˆ†æ', 
            'ğŸ“š æœŸåˆŠå½±å“åŠ›åˆ†æ',
            'ğŸŒ å›½å®¶åœ°åŒºåˆ†æ'
        ])
        with tabs[0]:
            st.markdown("""
            <div style="background: linear-gradient(135deg, rgba(192, 214, 234, 0.08) 0%, rgba(181, 168, 202, 0.08) 100%); padding: 25px; border-radius: 20px; margin-bottom: 25px; border: 1px solid rgba(181, 168, 202, 0.2); backdrop-filter: blur(10px); box-shadow: 0 8px 32px rgba(181, 168, 202, 0.1);">
                <h4 style="color: #2C3E50; font-size: 1.3rem; font-weight: 500; margin-bottom: 15px; letter-spacing: 0.3px;">ğŸ“ˆ æ€»ä½“ä¿¡æ¯æ¦‚è§ˆ</h4>
                <p style="color: #5A4B6B; font-size: 0.95rem; line-height: 1.6; margin: 0;">å±•ç¤ºæ–‡çŒ®æ•°æ®åº“çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬å‘æ–‡è¶‹åŠ¿ã€æ—¶é—´åˆ†å¸ƒã€æ ¸å¿ƒæŒ‡æ ‡ç­‰å…³é”®æ•°æ®ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
            number_of_total_unique_authors=process_Overall_Information_Overview_Tab(df,start, stop)
        with tabs[1]:
            st.markdown("""
            <div style="background: linear-gradient(135deg, rgba(192, 214, 234, 0.08) 0%, rgba(181, 168, 202, 0.08) 100%); padding: 25px; border-radius: 20px; margin-bottom: 25px; border: 1px solid rgba(181, 168, 202, 0.2); backdrop-filter: blur(10px); box-shadow: 0 8px 32px rgba(181, 168, 202, 0.1);">
                <h4 style="color: #2C3E50; font-size: 1.3rem; font-weight: 500; margin-bottom: 15px; letter-spacing: 0.3px;">ğŸ‘¥ å‘æ–‡ä½œè€…åˆ†æ</h4>
                <p style="color: #5A4B6B; font-size: 0.95rem; line-height: 1.6; margin: 0;">æ·±å…¥åˆ†æä½œè€…å‘æ–‡æƒ…å†µï¼Œè¯†åˆ«é«˜äº§ä½œè€…ã€åˆä½œç½‘ç»œã€å½±å“åŠ›è¯„ä¼°ç­‰å…³é”®æŒ‡æ ‡ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
            number_of_total_articles=df.shape[0]
            n_max,rounded_m,most_citiations,number_of_authors_publication_df=process_Publication_Author_Analysis_Tab(df,number_of_total_unique_authors,number_of_total_articles)
            process_Publication_Author_Tab_Most_Productive(n_max, rounded_m, most_citiations, number_of_authors_publication_df)
        with tabs[2]:
            st.markdown("""
            <div style="background: linear-gradient(135deg, rgba(192, 214, 234, 0.08) 0%, rgba(181, 168, 202, 0.08) 100%); padding: 25px; border-radius: 20px; margin-bottom: 25px; border: 1px solid rgba(181, 168, 202, 0.2); backdrop-filter: blur(10px); box-shadow: 0 8px 32px rgba(181, 168, 202, 0.1);">
                <h4 style="color: #2C3E50; font-size: 1.3rem; font-weight: 500; margin-bottom: 15px; letter-spacing: 0.3px;">ğŸ“š æœŸåˆŠå½±å“åŠ›åˆ†æ</h4>
                <p style="color: #5A4B6B; font-size: 0.95rem; line-height: 1.6; margin: 0;">è¯„ä¼°æœŸåˆŠçš„å­¦æœ¯å½±å“åŠ›ï¼Œåˆ†æå‘æ–‡åˆ†å¸ƒã€å¼•ç”¨æƒ…å†µã€æœŸåˆŠæ’åç­‰æ ¸å¿ƒæŒ‡æ ‡ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
            process_Journay_Analysis_Tab(df)
        with tabs[3]:
            st.markdown("""
            <div style="background: linear-gradient(135deg, rgba(192, 214, 234, 0.08) 0%, rgba(181, 168, 202, 0.08) 100%); padding: 25px; border-radius: 20px; margin-bottom: 25px; border: 1px solid rgba(181, 168, 202, 0.2); backdrop-filter: blur(10px); box-shadow: 0 8px 32px rgba(181, 168, 202, 0.1);">
                <h4 style="color: #2C3E50; font-size: 1.3rem; font-weight: 500; margin-bottom: 15px; letter-spacing: 0.3px;">ğŸŒ å›½å®¶åœ°åŒºåˆ†æ</h4>
                <p style="color: #5A4B6B; font-size: 0.95rem; line-height: 1.6; margin: 0;">åˆ†æç ”ç©¶çš„åœ°ç†åˆ†å¸ƒï¼Œè¯†åˆ«ä¸»è¦ç ”ç©¶å›½å®¶ã€å›½é™…åˆä½œæ¨¡å¼ã€åœ°åŒºå½±å“åŠ›ç­‰å…³é”®ä¿¡æ¯ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
            process_Country_Analysis_Tab(df)

