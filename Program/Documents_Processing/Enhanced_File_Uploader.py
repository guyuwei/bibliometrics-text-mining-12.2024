"""
å¢å¼ºçš„æ–‡ä»¶ä¸Šä¼ å¤„ç†å™¨
æ”¯æŒWOSã€CSVã€BIBç­‰å¤šç§æ–‡ä»¶æ ¼å¼
"""

import pandas as pd
import streamlit as st
import bibtexparser
from typing import Optional, Tuple
import io

def load_bib_file(uploaded_file) -> pd.DataFrame:
    """
    åŠ è½½å’Œè§£æBIBæ–‡ä»¶
    
    Args:
        uploaded_file: Streamlitä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
        
    Returns:
        pd.DataFrame: è§£æåçš„æ•°æ®æ¡†
    """
    try:
        # è¯»å–BIBæ–‡ä»¶å†…å®¹
        bib_content = uploaded_file.read().decode('utf-8')
        
        # è§£æBIBæ–‡ä»¶
        bib_database = bibtexparser.loads(bib_content)
        
        if not bib_database.entries:
            st.warning("BIBæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ–‡çŒ®æ¡ç›®")
            return pd.DataFrame()
        
        # è½¬æ¢ä¸ºDataFrame
        entries_list = []
        for entry in bib_database.entries:
            # æ ‡å‡†åŒ–å­—æ®µå
            standardized_entry = {}
            for field, value in entry.items():
                # ç§»é™¤BibTeXçš„å¤§æ‹¬å·
                clean_value = value.strip('{}')
                standardized_entry[field] = clean_value
            
            entries_list.append(standardized_entry)
        
        df = pd.DataFrame(entries_list)
        
        if df.empty:
            st.warning("BIBæ–‡ä»¶è§£ææˆåŠŸï¼Œä½†æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ–‡çŒ®æ•°æ®")
            return pd.DataFrame()
        
        # æ ‡å‡†åŒ–åˆ—åæ˜ å°„
        column_mapping = {
            'title': 'æ–‡çŒ®æ ‡é¢˜',
            'author': 'ä½œè€…',
            'journal': 'æœŸåˆŠåç§°',
            'year': 'å‡ºç‰ˆå¹´',
            'volume': 'å·',
            'number': 'æœŸ',
            'pages': 'é¡µç ',
            'doi': 'DOI',
            'abstract': 'æ‘˜è¦',
            'keywords': 'å…³é”®è¯',
            'publisher': 'å‡ºç‰ˆå•†',
            'booktitle': 'ä¹¦å',
            'editor': 'ç¼–è¾‘',
            'series': 'ä¸›ä¹¦',
            'address': 'åœ°å€',
            'url': 'URL',
            'isbn': 'ISBN',
            'issn': 'ISSN',
            'note': 'å¤‡æ³¨',
            'type': 'æ–‡çŒ®ç±»å‹',
            'ENTRYTYPE': 'æ–‡çŒ®ç±»å‹'
        }
        
        # é‡å‘½ååˆ—
        df = df.rename(columns=column_mapping)
        
        # å¤„ç†ä½œè€…å­—æ®µï¼ˆå¤šä¸ªä½œè€…ç”¨åˆ†å·åˆ†éš”ï¼‰
        if 'ä½œè€…' in df.columns:
            df['ä½œè€…'] = df['ä½œè€…'].astype(str).str.replace(' and ', '; ')
        
        # å¤„ç†å¹´ä»½å­—æ®µ
        if 'å‡ºç‰ˆå¹´' in df.columns:
            df['å‡ºç‰ˆå¹´'] = pd.to_numeric(df['å‡ºç‰ˆå¹´'], errors='coerce')
        
        # å¤„ç†é¡µç å­—æ®µ
        if 'é¡µç ' in df.columns:
            df['é¡µç '] = df['é¡µç '].astype(str)
        
        # æ˜¾ç¤ºè§£æç»“æœ
        st.success(f"âœ… BIBæ–‡ä»¶è§£ææˆåŠŸï¼")
        st.info(f"ğŸ“ æ–‡ä»¶å: {uploaded_file.name}")
        st.info(f"ğŸ“š è§£æåˆ° {len(df)} æ¡æ–‡çŒ®è®°å½•")
        
        # æ˜¾ç¤ºå­—æ®µç»Ÿè®¡
        if not df.empty:
            field_stats = {
                'å­—æ®µå': list(df.columns),
                'éç©ºè®°å½•æ•°': [df[col].notna().sum() for col in df.columns],
                'æ•°æ®ç±»å‹': [str(df[col].dtype) for col in df.columns]
            }
            field_df = pd.DataFrame(field_stats)
            st.dataframe(field_df, use_container_width=True)
        
        return df
        
    except Exception as e:
        st.error(f"è§£æBIBæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return pd.DataFrame()

def load_csv_file(uploaded_file) -> pd.DataFrame:
    """
    åŠ è½½CSVæ–‡ä»¶
    
    Args:
        uploaded_file: Streamlitä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
        
    Returns:
        pd.DataFrame: è§£æåçš„æ•°æ®æ¡†
    """
    try:
        # å°è¯•å¤šç§ç¼–ç æ–¹å¼è¯»å–CSVæ–‡ä»¶
        encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252', 'gbk']
        df = None
        
        for encoding in encodings:
            try:
                uploaded_file.seek(0)
                df = pd.read_csv(io.StringIO(uploaded_file.read().decode(encoding)))
                break
            except (UnicodeDecodeError, pd.errors.EmptyDataError):
                continue
        
        if df is None:
            st.error("æ— æ³•è¯»å–CSVæ–‡ä»¶ï¼šä¸æ”¯æŒçš„æ–‡ä»¶ç¼–ç æ ¼å¼")
            return pd.DataFrame()
        
        if df.empty:
            st.warning("CSVæ–‡ä»¶ä¸ºç©º")
            return pd.DataFrame()
        
        st.success(f"âœ… CSVæ–‡ä»¶åŠ è½½æˆåŠŸï¼")
        st.info(f"ğŸ“ æ–‡ä»¶å: {uploaded_file.name}")
        st.info(f"ğŸ“š è§£æåˆ° {len(df)} æ¡è®°å½•")
        
        return df
        
    except Exception as e:
        st.error(f"åŠ è½½CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return pd.DataFrame()

@st.cache_data
def load_file_universal(uploaded_file) -> pd.DataFrame:
    """
    é€šç”¨æ–‡ä»¶åŠ è½½å‡½æ•°ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    
    Args:
        uploaded_file: Streamlitä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
        
    Returns:
        pd.DataFrame: è§£æåçš„æ•°æ®æ¡†
    """
    if uploaded_file is None:
        return pd.DataFrame()
    
    file_extension = uploaded_file.name.lower().split('.')[-1]
    
    try:
        if file_extension == 'txt':
            # ä½¿ç”¨å¢å¼ºçš„WOSè§£æå™¨
            try:
                from .Uploading_Files import Load_TXT_Enhanced
                return Load_TXT_Enhanced(uploaded_file)
            except ImportError:
                from .Uploading_Files import Load_TXT
                return Load_TXT(uploaded_file)
                
        elif file_extension == 'csv':
            return load_csv_file(uploaded_file)
            
        elif file_extension == 'bib':
            return load_bib_file(uploaded_file)
            
        else:
            st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .{file_extension}")
            st.info("æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .txt (WOS), .csv, .bib")
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return pd.DataFrame()

def create_enhanced_file_uploader(label: str, supported_types: list, key: str = None) -> Optional[object]:
    """
    åˆ›å»ºå¢å¼ºçš„æ–‡ä»¶ä¸Šä¼ å™¨
    
    Args:
        label: ä¸Šä¼ å™¨æ ‡ç­¾
        supported_types: æ”¯æŒçš„æ–‡ä»¶ç±»å‹åˆ—è¡¨
        key: ç»„ä»¶key
        
    Returns:
        æ–‡ä»¶ä¸Šä¼ å™¨å¯¹è±¡
    """
    # æ–‡ä»¶ç±»å‹è¯´æ˜
    type_descriptions = {
        'txt': 'WOSå¯¼å‡ºæ–‡ä»¶ (.txt)',
        'csv': 'CSVæ•°æ®æ–‡ä»¶ (.csv)', 
        'bib': 'BibTeXæ–‡çŒ®æ–‡ä»¶ (.bib)'
    }
    
    # åˆ›å»ºç±»å‹è¯´æ˜æ–‡æœ¬
    type_text = " | ".join([type_descriptions.get(t, t) for t in supported_types])
    
    st.markdown(f"""
    <div style="margin-bottom: 10px;">
        <p style="color: #5A4B6B; font-size: 0.9rem; margin: 0;">ğŸ’¡ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {type_text}</p>
    </div>
    """, unsafe_allow_html=True)
    
    return st.file_uploader(
        label,
        type=supported_types,
        key=key,
        help=f"æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {', '.join(supported_types)}"
    )

def validate_file_format(uploaded_file) -> Tuple[bool, str]:
    """
    éªŒè¯ä¸Šä¼ æ–‡ä»¶çš„æ ¼å¼
    
    Args:
        uploaded_file: ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
        
    Returns:
        Tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
    """
    if uploaded_file is None:
        return False, "è¯·é€‰æ‹©æ–‡ä»¶"
    
    file_extension = uploaded_file.name.lower().split('.')[-1]
    supported_types = ['txt', 'csv', 'bib']
    
    if file_extension not in supported_types:
        return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .{file_extension}ã€‚æ”¯æŒæ ¼å¼: {', '.join(supported_types)}"
    
    return True, "æ–‡ä»¶æ ¼å¼æœ‰æ•ˆ"
